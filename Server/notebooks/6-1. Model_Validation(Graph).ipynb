{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import itertools\n",
    "\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from eunjeon import Mecab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../analysis_files/files/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성대화말뭉치(최종데이터)_Training.csv 파일을 pandas로 읽어옵니다.\n",
    "df = pd.read_csv(os.path.join(data_dir, '감성대화말뭉치(최종데이터)_Validation.csv'), encoding='cp949')\n",
    "df = df[['사람문장1', '시스템문장1', '사람문장2','시스템문장2','사람문장3','시스템문장3','감정_대분류', '상황키워드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELMo 모델 초기화\n",
    "options_file = \"../analysis_files/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weight_file = \"../analysis_files/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "elmo = Elmo(options_file, weight_file, num_output_representations=1)\n",
    "\n",
    "# mecab 모델 다운로드\n",
    "mecab = Mecab()\n",
    "\n",
    "# elmo 모델 다운로드\n",
    "elmo = elmo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 문장 형태소 분리 함수\n",
    "def tokenize_korean_sentence(sentence):\n",
    "    tokens = mecab.morphs(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentences) :\n",
    "    sentences = re.sub(r'\\([^)]*\\)', '', sentences)\n",
    "    sentences = sentences.replace('.', '')\n",
    "    sentences = re.sub(r'[^가-힣\\s]', '', sentences)\n",
    "    sentences = re.sub(r'\\b(?:cm|km|etc)\\b', '', sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence_features(sentence):\n",
    "    # TF-IDF 벡터화 객체 생성\n",
    "    tfidf_vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "    # 문장 길이\n",
    "    sentence_length = len(sentence)\n",
    "\n",
    "    # 품사 개수\n",
    "    tokens = mecab.pos(sentence)\n",
    "    pos_tags = [tag for _, tag in tokens]\n",
    "    num_pos_tags = len(pos_tags)\n",
    "\n",
    "    # 명사 추출\n",
    "    nouns = mecab.nouns(sentence)\n",
    "\n",
    "    # TF-IDF 벡터화 및 상위 3개 단어 추출\n",
    "    top_words = ['', '', '']  # 단어가 없을 경우 빈 문자열로 초기화\n",
    "    top_scores = [0.0, 0.0, 0.0]  # 단어가 없을 경우 TF-IDF 스코어를 0.0으로 초기화\n",
    "    top_word_vectors = np.zeros((3,))  # 단어가 없을 경우 0 벡터로 초기화\n",
    "\n",
    "    if nouns:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(nouns)\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        tfidf_scores = tfidf_matrix.toarray()[0]\n",
    "        top_indices = np.argsort(tfidf_scores)[-3:][::-1]  # 상위 3개 단어의 인덱스 추출\n",
    "        top_words = [feature_names[index] for index in top_indices]  # 상위 3개 단어 추출\n",
    "        top_scores = [tfidf_scores[index] for index in top_indices]  # 상위 3개 단어의 TF-IDF 스코어 추출\n",
    "        top_word_vectors = [tfidf_matrix.toarray()[0][index] for index in top_indices]  # 상위 3개 단어의 벡터값 추출\n",
    "\n",
    "    return sentence_length, num_pos_tags, top_words, top_scores, top_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "data_test = []\n",
    "\n",
    "# 레이블을 정수형으로 변환\n",
    "label_mapping_emotion = {'기쁨': 0, '당황': 1, '분노': 2, '불안' : 3, '상처' : 4,'슬픔' : 5}  # 감정에 해당하는 레이블과 정수 매핑\n",
    "label_mapping_situation = {'가족관계': 0, '건강': 1, '건강,죽음': 2, '대인관계' : 3, '대인관계(부부, 자녀)' : 4, '연애,결혼,출산' : 5, '재정' : 6, '재정,은퇴,노후준비' : 7, '직장, 업무 스트레스' : 8, '진로,취업,직장' : 9, '학교폭력/따돌림' : 10, '학업 및 진로' : 11}  # 상황에 해당하는 레이블과 정수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_add_similarity(G, i, source_node, target_node):\n",
    "    prev_sentence_embedding = G.nodes[source_node]['feature']\n",
    "    curr_sentence_embedding = G.nodes[target_node]['feature']\n",
    "\n",
    "    # 코사인 유사도를 계산하기 위해 두 벡터를 같은 크기로 변경 (1차원으로 변환)\n",
    "    prev_sentence_embedding = prev_sentence_embedding.view(-1)\n",
    "    curr_sentence_embedding = curr_sentence_embedding.view(-1)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity_score = F.cosine_similarity(prev_sentence_embedding, curr_sentence_embedding, dim=0)\n",
    "\n",
    "    # 엣지 특성으로 추가\n",
    "    G.edges[source_node, target_node]['sentence_similarity'] = similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 최대 길이를 30으로 설정\n",
    "max_sentence_length = 30\n",
    "\n",
    "# 그래프 생성 및 노드 추가\n",
    "graphs = []\n",
    "for _, row in df.iterrows():\n",
    "    G = nx.Graph()\n",
    "    sentences = [row['사람문장1'], row['시스템문장1'], row['사람문장2'], row['시스템문장2'], row['사람문장3'], row['시스템문장3']]\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        print(i, sentence)\n",
    "        if pd.isna(sentence):  # NaN 값 처리\n",
    "            sentence_embedding = torch.zeros(max_sentence_length, 1024).to(device)  # 0 벡터로 처리\n",
    "        else:\n",
    "            sentence = preprocessing(sentence)\n",
    "            # 문장을 형태소로 분리\n",
    "            tokens = tokenize_korean_sentence(sentence)\n",
    "            # 문장을 ELMo 임베딩으로 변환\n",
    "            character_ids = batch_to_ids([tokens]).to(device)  # GPU로 이동\n",
    "            embeddings_output = elmo(character_ids)  # GPU로 이동\n",
    "            sentence_embedding = torch.mean(embeddings_output[\"elmo_representations\"][0], dim=0).to('cpu')\n",
    "            # 문장 특징 추출\n",
    "            sentence_length, num_pos_tags, top_words, top_scores, top_word_vectors = extract_sentence_features(sentence)\n",
    "\n",
    "            # 변환된 특징 데이터를 텐서로 변환\n",
    "            sentence_embedding_tensor = torch.tensor(sentence_embedding)\n",
    "\n",
    "            # 문장의 길이를 확인하고 부족한 부분을 0 벡터로 패딩\n",
    "            if sentence_embedding_tensor.size(0) < max_sentence_length:\n",
    "                padding_size = max_sentence_length - sentence_embedding_tensor.size(0)\n",
    "                padding_tensor = torch.zeros(padding_size, 1024)\n",
    "                sentence_embedding_tensor = torch.cat([sentence_embedding_tensor, padding_tensor], dim=0)\n",
    "\n",
    "            # 문장의 길이가 최대 길이를 초과하는 경우, 최대 길이까지만 남기고 잘라줌\n",
    "            sentence_embedding_tensor = sentence_embedding_tensor[:max_sentence_length]\n",
    "\n",
    "            length_tensor = torch.tensor(sentence_length)\n",
    "            pos_tags_tensor = torch.tensor(num_pos_tags)\n",
    "            top_word_vectors_tensor = torch.tensor(top_word_vectors)\n",
    "\n",
    "        G.add_node(i)\n",
    "\n",
    "        # 노드 특성 추가\n",
    "        G.nodes[i]['feature'] = sentence_embedding_tensor\n",
    "        G.nodes[i]['length'] = length_tensor\n",
    "        G.nodes[i]['pos_tags'] = pos_tags_tensor\n",
    "        G.nodes[i]['top_word_vectors'] = top_word_vectors_tensor\n",
    "\n",
    "        if i > 0:\n",
    "            # 엣지 정보 생성\n",
    "            edge_index = i-1  # 엣지 번호\n",
    "            G.add_edge(i-1, i, edge_index=edge_index)  # 엣지 정보는 인덱스로 설정\n",
    "\n",
    "            # 엣지의 추가적인 특성 추가 (sentence_similarity, edge_type)\n",
    "            calculate_and_add_similarity(G, i, i - 1, i)\n",
    "\n",
    "            if i in [1, 3]:\n",
    "                edge_type = 1 # 사람\n",
    "                G.add_edge(i-1, i+1, edge_type=edge_type)\n",
    "\n",
    "            elif i in [2, 4]:\n",
    "                edge_type = 2 # 시스템\n",
    "                G.add_edge(i-1, i+1, edge_type=edge_type)\n",
    "                calculate_and_add_similarity(G, i, i - 2, i)\n",
    "            else :\n",
    "                continue\n",
    "\n",
    "    # 감정 및 상황 레이블 할당\n",
    "    y_emotion = label_mapping_emotion[row['감정_대분류']]\n",
    "    y_situation = label_mapping_situation[row['상황키워드']]\n",
    "\n",
    "    graphs.append((G, y_emotion, y_situation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 시각화\n",
    "for i in range(4):  # 3개의 그래프만 표시\n",
    "    graph, _, _ = graphs[i]  # graph, y_emotion, y_situation 중 graph만 사용\n",
    "    pos = nx.spring_layout(graph)  # 그래프의 노드 위치 결정\n",
    "    nx.draw(graph, pos, with_labels=True, node_color='lightblue', edge_color='gray', font_size=8)  # 그래프 그리기\n",
    "    node_attributes = graph.nodes(data=True)  # 노드의 속성 정보 가져오기\n",
    "    edge_attributes = graph.edges(data=True)  # 엣지의 속성 정보 가져오기\n",
    "\n",
    "\n",
    "    # for node, attributes in node_attributes:\n",
    "    #     x, y = pos[node]\n",
    "    #     # 노드 속성 표시\n",
    "    #     attribute_text = f\"Node: {node}\\n\"\n",
    "    #     for attr_name, attr_value in attributes.items():\n",
    "    #         attribute_text += f\"{attr_name.capitalize()}: {attr_value}\\n\"\n",
    "    #     plt.text(x, y + 0.05, s=attribute_text, fontsize=6, ha='center', va='bottom')\n",
    "\n",
    "    for edge in edge_attributes:\n",
    "        x1, y1 = pos[edge[0]]\n",
    "        x2, y2 = pos[edge[1]]\n",
    "        # 엣지 속성 표시\n",
    "        attribute_text = f\"Edge: {edge[0]}-{edge[1]}\\n\"\n",
    "        for attr_name, attr_value in edge[2].items():\n",
    "            attribute_text += f\"{attr_name.capitalize()}: {attr_value}\\n\"\n",
    "        plt.text((x1 + x2) / 2, (y1 + y2) / 2, s=attribute_text, fontsize=6, ha='center', va='bottom')\n",
    "\n",
    "    # y_emotion과 y_situation 레이블 표시\n",
    "    # y_emotion = label_mapping_emotion[row['감정_대분류']]\n",
    "    # y_situation = label_mapping_situation[row['상황키워드']]\n",
    "    # plt.text(0, 1.1, s=f\"y_emotion: {y_emotion}\", fontsize=8, ha='center', va='bottom')\n",
    "    # plt.text(0, 1.05, s=f\"y_situation: {y_situation}\", fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl_graphs = []\n",
    "for (G, y_emotion, y_situation) in graphs:\n",
    "    # Convert NetworkX graph to DGL graph\n",
    "    dgl_G = dgl.DGLGraph(G)\n",
    "    # 노드 및 엣지 속성을 graph.ndata 및 graph.edata에 저장\n",
    "    num_nodes = len(G.nodes())\n",
    "    num_edges = len(G.edges())\n",
    "    dgl_G.ndata['feature'] = torch.zeros(num_nodes, 1024)\n",
    "    dgl_G.ndata['length'] = torch.zeros(num_nodes , 1)\n",
    "    dgl_G.ndata['pos_tags'] = torch.zeros(num_nodes, 1)\n",
    "    dgl_G.ndata['top_word_vectors'] = torch.zeros(num_nodes, 3)  # top_word_vectors의 크기를 3으로 고정\n",
    "    dgl_G.edata['edge_type'] = torch.zeros(num_edges * 2, 1)\n",
    "    dgl_G.edata['sentence_similarity'] = torch.zeros(num_edges * 2, 1)\n",
    "\n",
    "    for i in G.nodes():\n",
    "        feature = G.nodes[i]['feature']\n",
    "        if feature.shape != (1024,):\n",
    "            # feature의 크기가 (1024,)가 아닌 경우, 1024 차원의 평균을 취하여 크기를 (1024,)로 축소\n",
    "            feature = torch.mean(feature, dim=0)\n",
    "        dgl_G.ndata['feature'][i] = feature\n",
    "        dgl_G.ndata['length'][i] = G.nodes[i]['length']\n",
    "        dgl_G.ndata['pos_tags'][i] = G.nodes[i]['pos_tags']\n",
    "        top_word_vectors = G.nodes[i]['top_word_vectors']\n",
    "        if top_word_vectors.shape != (3,):\n",
    "            # top_word_vectors의 크기가 (3,)가 아닌 경우, 3 차원으로 크기를 고정하고 0으로 채워진 텐서로 변환\n",
    "            top_word_vectors = torch.tensor(top_word_vectors)\n",
    "            expanded_top_word_vectors = torch.zeros(3)\n",
    "            expanded_top_word_vectors[:top_word_vectors.size(0)] = top_word_vectors\n",
    "            top_word_vectors = expanded_top_word_vectors\n",
    "        dgl_G.ndata['top_word_vectors'][i] = top_word_vectors\n",
    "\n",
    "    for i, j in G.edges():\n",
    "        if 'edge_type' in G.edges[i, j]:\n",
    "            dgl_G.edata['edge_type'][j-1] = G.edges[i, j]['edge_type']\n",
    "        else:\n",
    "            dgl_G.edata['edge_type'][j-1] = 0\n",
    "\n",
    "        if 'sentence_similarity' in G.edges[i, j]:\n",
    "            dgl_G.edata['sentence_similarity'][j] = G.edges[i, j]['sentence_similarity']\n",
    "        else:\n",
    "            dgl_G.edata['sentence_similarity'][j] = 0\n",
    "\n",
    "    dgl_G.ndata['y_emotion'] = torch.tensor([y_emotion] * num_nodes)\n",
    "    dgl_G.ndata['y_situation'] = torch.tensor([y_situation] * num_nodes)\n",
    "\n",
    "    dgl_graphs.append(dgl_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    graph = dgl_graphs[i]\n",
    "    print(f\"Graph {i+1}:\")\n",
    "    print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"Number of edges:\", graph.number_of_edges())\n",
    "    print(\"Node features:\")\n",
    "    print(graph.ndata)\n",
    "    print(\"Edge features:\")\n",
    "    print(graph.edata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "train_graphs, test_graphs = train_test_split(dgl_graphs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = dgl.nn.SAGEConv(input_dim, hidden_dim, 'mean')  # SAGEConv를 사용하여 엣지 속성을 노드로 전파\n",
    "        self.conv2 = dgl.nn.SAGEConv(hidden_dim, hidden_dim, 'mean')\n",
    "        self.conv3 = dgl.nn.SAGEConv(hidden_dim, hidden_dim, 'mean')\n",
    "        self.fc_emotion = nn.Linear(hidden_dim, output_dim['emotion'])\n",
    "        self.fc_situation = nn.Linear(hidden_dim, output_dim['situation'])\n",
    "        self.linear_transform = nn.Linear(input_dim-5, hidden_dim)\n",
    "        self.linear_transform2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "    def forward(self, g):\n",
    "        x = g.ndata['feature']\n",
    "        length = g.ndata['length'].view(-1, 1)\n",
    "        pos_tags = g.ndata['pos_tags'].view(-1, 1)\n",
    "        top_word_vectors = g.ndata['top_word_vectors']\n",
    "        sentence_similarity = g.edata['sentence_similarity']\n",
    "        sentence_similarity = self.linear_transform(sentence_similarity)\n",
    "\n",
    "        # 속성들을 모델에 입력으로 추가\n",
    "        x = torch.cat([x, length, pos_tags, top_word_vectors], dim=1)\n",
    "        x = self.conv1(g, x, edge_weight=sentence_similarity)  # SAGEConv에 sentence_similarity 엣지 속성 전달\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(g, x, edge_weight=sentence_similarity)  # SAGEConv에 sentence_similarity 엣지 속성 전달\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(g, x, edge_weight=sentence_similarity)  # SAGEConv에 sentence_similarity 엣지 속성 전달\n",
    "        x = F.relu(x)\n",
    "\n",
    "        sentence_similarity=sentence_similarity[:192]\n",
    "        if sentence_similarity.shape == (192, 128) and x.shape == (192, 128):\n",
    "            # 엣지 속성을 노드 속성과 함께 연결하여 모델의 입력으로 사용\n",
    "            x = torch.cat([x, sentence_similarity], dim=1)\n",
    "            x = self.linear_transform2(x)\n",
    "            emotion_out = self.fc_emotion(x)\n",
    "            situation_out = self.fc_situation(x)\n",
    "        else :\n",
    "            emotion_out = torch.zeros(192, 6)\n",
    "            situation_out = torch.zeros(192, 12)\n",
    "\n",
    "        return emotion_out, situation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 초기화 및 손실 함수, 옵티마이저 설정\n",
    "input_dim = 1029\n",
    "hidden_dim = 128\n",
    "learning_rate = 0.001\n",
    "output_dim = {'emotion': len(label_mapping_emotion), 'situation': len(label_mapping_situation)}\n",
    "model = GCNModel(input_dim, hidden_dim, output_dim)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "batch_size = 32\n",
    "train_loader = GraphDataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "test_loader = GraphDataLoader(test_graphs, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true_emotion = []\n",
    "    y_pred_emotion = []\n",
    "    y_true_situation = []\n",
    "    y_pred_situation = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            g = batch\n",
    "            labels_emotion = g.ndata['y_emotion']\n",
    "            labels_situation = g.ndata['y_situation']\n",
    "\n",
    "            # Pad labels_emotion and labels_situation to size (192,) if they are smaller\n",
    "            if labels_emotion.shape[0] < 192:\n",
    "                padding_dim = 192 - labels_emotion.shape[0]\n",
    "                labels_emotion = F.pad(labels_emotion, (0, padding_dim), value=0)\n",
    "                labels_emotion = labels_emotion.clone().detach()  # Detach the tensor from the computation graph\n",
    "            if labels_situation.shape[0] < 192:\n",
    "                padding_dim = 192 - labels_situation.shape[0]\n",
    "                labels_situation = F.pad(labels_situation, (0, padding_dim), value=0)\n",
    "                labels_situation = labels_situation.clone().detach()  # Detach the tensor from the computation graph\n",
    "\n",
    "\n",
    "            outputs_emotion, outputs_situation = model(g)\n",
    "            _, predicted_emotion = torch.max(outputs_emotion, 1)\n",
    "            _, predicted_situation = torch.max(outputs_situation, 1)\n",
    "            y_true_emotion.extend(labels_emotion.tolist())\n",
    "            y_pred_emotion.extend(predicted_emotion.tolist())\n",
    "            y_true_situation.extend(labels_situation.tolist())\n",
    "            y_pred_situation.extend(predicted_situation.tolist())\n",
    "\n",
    "    accuracy_emotion = accuracy_score(y_true_emotion, y_pred_emotion)\n",
    "    recall_emotion = recall_score(y_true_emotion, y_pred_emotion, average='macro')\n",
    "    f1_emotion = f1_score(y_true_emotion, y_pred_emotion, average='macro')\n",
    "    accuracy_situation = accuracy_score(y_true_situation, y_pred_situation)\n",
    "    recall_situation = recall_score(y_true_situation, y_pred_situation, average='macro')\n",
    "    f1_situation = f1_score(y_true_situation, y_pred_situation, average='macro')\n",
    "\n",
    "    return accuracy_emotion, recall_emotion, f1_emotion, accuracy_situation, recall_situation, f1_situation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_acc_emotion_list = []\n",
    "train_acc_situation_list = []\n",
    "test_acc_emotion_list = []\n",
    "test_acc_situation_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch in test_loader:\n",
    "        g = batch\n",
    "        labels_emotion = g.ndata['y_emotion']\n",
    "        labels_situation = g.ndata['y_situation']\n",
    "\n",
    "        # Pad labels_emotion and labels_situation to size (192,) if they are smaller\n",
    "        if labels_emotion.shape[0] < 192:\n",
    "            padding_dim = 192 - labels_emotion.shape[0]\n",
    "            labels_emotion = F.pad(labels_emotion, (0, padding_dim), value=0)\n",
    "            labels_emotion = labels_emotion.clone().detach()  # Detach the tensor from the computation graph\n",
    "        if labels_situation.shape[0] < 192:\n",
    "            padding_dim = 192 - labels_situation.shape[0]\n",
    "            labels_situation = F.pad(labels_situation, (0, padding_dim), value=0)\n",
    "            labels_situation = labels_situation.clone().detach()  # Detach the tensor from the computation graph\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs_emotion, outputs_situation = model(g)\n",
    "        loss_emotion = loss_function(outputs_emotion, labels_emotion)\n",
    "        loss_situation = loss_function(outputs_situation, labels_situation)\n",
    "        loss = loss_emotion + loss_situation\n",
    "        if loss.requires_grad:  # loss를 계산할 필요가 있는 경우에만 backward를 수행\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    for batch in train_loader:\n",
    "        g = batch\n",
    "        labels_emotion = g.ndata['y_emotion']\n",
    "        labels_situation = g.ndata['y_situation']\n",
    "\n",
    "        # Pad labels_emotion and labels_situation to size (192,) if they are smaller\n",
    "        if labels_emotion.shape[0] < 192:\n",
    "            padding_dim = 192 - labels_emotion.shape[0]\n",
    "            labels_emotion = F.pad(labels_emotion, (0, padding_dim), value=0)\n",
    "            labels_emotion = labels_emotion.clone().detach()  # Detach the tensor from the computation graph\n",
    "        if labels_situation.shape[0] < 192:\n",
    "            padding_dim = 192 - labels_situation.shape[0]\n",
    "            labels_situation = F.pad(labels_situation, (0, padding_dim), value=0)\n",
    "            labels_situation = labels_situation.clone().detach()  # Detach the tensor from the computation graph\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs_emotion, outputs_situation = model(g)\n",
    "        loss_emotion = loss_function(outputs_emotion, labels_emotion)\n",
    "        loss_situation = loss_function(outputs_situation, labels_situation)\n",
    "        loss = loss_emotion + loss_situation\n",
    "        if loss.requires_grad:  # loss를 계산할 필요가 있는 경우에만 backward를 수행\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # 학습 데이터에 대한 평가\n",
    "    train_accuracy_emotion, train_recall_emotion, train_f1_emotion, train_accuracy_situation, train_recall_situation, train_f1_situation = evaluate(model, train_loader)\n",
    "    # 테스트 데이터에 대한 평가\n",
    "    test_accuracy_emotion, test_recall_emotion, test_f1_emotion, test_accuracy_situation, test_recall_situation, test_f1_situation = evaluate(model, test_loader)\n",
    "\n",
    "    # Append accuracy values to the lists\n",
    "    train_acc_emotion_list.append(train_accuracy_emotion)\n",
    "    train_acc_situation_list.append(train_accuracy_situation)\n",
    "    test_acc_emotion_list.append(test_accuracy_emotion)\n",
    "    test_acc_situation_list.append(test_accuracy_situation)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Emotion Accuracy: {train_accuracy_emotion:.4f} Recall: {train_recall_emotion:.4f} F1-score: {train_f1_emotion:.4f}\")\n",
    "    print(f\"Train Situation Accuracy: {train_accuracy_situation:.4f} Recall: {train_recall_situation:.4f} F1-score: {train_f1_situation:.4f}\")\n",
    "    print(f\"Test Emotion Accuracy: {test_accuracy_emotion:.4f} Recall: {test_recall_emotion:.4f} F1-score: {test_f1_emotion:.4f}\")\n",
    "    print(f\"Test Situation Accuracy: {test_accuracy_situation:.4f} Recall: {test_recall_situation:.4f} F1-score: {test_f1_situation:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy trend\n",
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "plt.plot(epochs, train_acc_emotion_list, label='Train Emotion Accuracy')\n",
    "plt.plot(epochs, train_acc_situation_list, label='Train Situation Accuracy')\n",
    "plt.plot(epochs, test_acc_emotion_list, label='Test Emotion Accuracy')\n",
    "plt.plot(epochs, test_acc_situation_list, label='Test Situation Accuracy')\n",
    "\n",
    "plt.title('Accuracy Trend')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
